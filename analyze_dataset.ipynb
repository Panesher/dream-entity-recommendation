{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from model_utils.thswad import load_model_from_transe\n",
    "from model_utils.trainer import THSWADTrainer\n",
    "from utils.ds import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/admin/dream-entity-recommendation/utils/ds.py:64: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if np.all(np.array(prev) == pad_item):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24610\n",
      "329191\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import json\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BS = 256\n",
    "VAL_BS = 4\n",
    "PREV_CNT = 5\n",
    "\n",
    "\n",
    "def make_item2id(el_single_train):\n",
    "    ds_ = DialogDataset(el_single_train['entity_ids'], 'pad', PREV_CNT)\n",
    "    items2id = {}\n",
    "    for i, (prev, next_id) in enumerate(ds_):\n",
    "        for item in prev:\n",
    "            if item not in items2id and item != 'pad':\n",
    "                items2id[item] = len(items2id)\n",
    "        if next_id not in items2id and next_id != 'pad':\n",
    "            items2id[next_id] = len(items2id)\n",
    "    return items2id\n",
    "\n",
    "with open(config['dataset']['postprocess']['train'], 'r') as f:\n",
    "    el_single_results = json.load(f)\n",
    "items2id = make_item2id(el_single_results)\n",
    "id2items = list(items2id.keys())\n",
    "\n",
    "\n",
    "def make_dataloader(el_single_res, wikidata_ds, items2id=items2id, batch_size=BS, shuffle=True):\n",
    "    ds = DialogDataset(el_single_res['entity_ids'], len(items2id), PREV_CNT, items2id)\n",
    "    print(len(ds))\n",
    "    dl = DataLoader(ds, batch_size=batch_size, shuffle=shuffle)\n",
    "    wdl = DataLoader(wikidata_ds, batch_size=batch_size, shuffle=shuffle)\n",
    "    return TSHWADLoader(wdl, dl)\n",
    "\n",
    "\n",
    "with open(config['dataset']['postprocess']['val'], 'r') as f:\n",
    "    el_val = json.load(f)\n",
    "val_loader = make_dataloader(el_val, [], batch_size=VAL_BS, shuffle=False)\n",
    "train_loader = make_dataloader(el_single_results, [], batch_size=VAL_BS, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1913172209598568, 18894)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "t = 0\n",
    "items_same = defaultdict(lambda: 0) \n",
    "items = defaultdict(lambda: 0)\n",
    "all_items_set = set()\n",
    "for i, b_ in enumerate(train_loader):\n",
    "    s = 0.\n",
    "    for x, y in zip(b_['ratings'][0], b_['ratings'][1]):\n",
    "        all_items_set.add(y.item())\n",
    "        for v in x:\n",
    "            all_items_set.add(v.item())\n",
    "\n",
    "        s += y in x\n",
    "        items[y.item()] += 1\n",
    "        if y in x:\n",
    "            items_same[y.item()] += 1\n",
    "    t += s / b_['ratings'][0].shape[0]\n",
    "\n",
    "t / i, len(all_items_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config['wikidata']['transe'], \"rb\") as f:\n",
    "    transe = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id2entity_id = []\n",
    "for id, item in enumerate(id2items):\n",
    "    item_id2entity_id.append(transe.graph.entity2id[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_embeddings = np.zeros((len(item_id2entity_id) + 1, transe.solver.entity_embeddings.shape[1]))\n",
    "for i, ent in enumerate(item_id2entity_id):\n",
    "    item_embeddings[i] = transe.solver.entity_embeddings[ent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk_numpy(a, v, k=10):\n",
    "    x = np.sum(np.abs(a - v), 1)\n",
    "    t = np.argpartition(x, k)[:k]\n",
    "    kv = [(x[v], v) for v in t]\n",
    "    kv.sort(key=lambda v: v[0])\n",
    "    return [v[1] for v in kv]\n",
    "\n",
    "\n",
    "def get_top_k_entities_numpy(entity, k=10):\n",
    "    return get_topk_numpy(item_embeddings, item_embeddings[entity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6153it [37:48,  2.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.06424739921976592, 0.0588832899869961, tensor(0.0493))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "map10 = 0.\n",
    "map5 = 0.\n",
    "accuracy = 0.\n",
    "for i, b_ in tqdm(enumerate(val_loader)):\n",
    "    map10_b = 0.\n",
    "    map5_b = 0.\n",
    "    accuracy_b = 0.\n",
    "    for x, y in zip(b_['ratings'][0], b_['ratings'][1]):\n",
    "        le = x[-1]\n",
    "        y = y\n",
    "        top10 = get_top_k_entities_numpy(le)\n",
    "        map10_b += y in top10\n",
    "        map5_b += y in top10[:5]\n",
    "        accuracy_b += y == top10[0]\n",
    "\n",
    "    map10 += map10_b / b_['ratings'][0].shape[0]\n",
    "    map5 += map5_b / b_['ratings'][0].shape[0]\n",
    "    accuracy += accuracy_b / b_['ratings'][0].shape[0]\n",
    "\n",
    "map10 / i, map5 / i, accuracy / i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map@10 0.064, map@5 0.059, accuracy 0.049\n"
     ]
    }
   ],
   "source": [
    "print('map@10 %.3f' % (map10 / i), 'map@5 %.3f' % (map5 / i), 'accuracy %.3f' % (accuracy / i), sep=', ')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daily dialog map@10 0.097, map@5 0.093, accuracy 0.087\n",
    "\n",
    "Dream vs ChatGPT map@10 0.155, map@5 0.141, accuracy 0.123\n",
    "\n",
    "Topical-Chat map@10 0.064, map@5 0.059, accuracy 0.049"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
